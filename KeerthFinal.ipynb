{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5djb25uRae2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5aae658-fbd1-4be0-f42a-aab0a7574bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading Faker-25.8.0-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lorem-text\n",
            "  Downloading lorem_text-2.1-py2.py3-none-any.whl (6.0 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.10/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.10/dist-packages (from lorem-text) (8.1.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
            "Installing collected packages: lorem-text, faker\n",
            "Successfully installed faker-25.8.0 lorem-text-2.1\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Mounted at /content/drive\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00494 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00497 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00494 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00486 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00482 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00485 (2).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00497 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00482 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00489 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00484 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00492 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00494 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00484 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00487 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00489 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00481 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00495 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00489 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00486 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00492 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00484 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00487 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00485 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00493 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/real/real_00490 (1).jpg\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/fake/train.csv\n",
            "Warning: Failed to load image: /content/drive/MyDrive/Fake Profile Dectection/fake/train.csv\n",
            "1/1 [==============================] - 1s 692ms/step\n",
            "0 [D loss: 7.988377064466476 | D accuracy: 28.125] [G loss: 0.22583188116550446]\n",
            "1/1 [==============================] - 0s 408ms/step\n",
            "1/1 [==============================] - 0s 393ms/step\n",
            "1 [D loss: 2.6582942189506866 | D accuracy: 50.0] [G loss: 1.2064039707183838]\n",
            "1/1 [==============================] - 0s 378ms/step\n",
            "2 [D loss: 1.2768265530467033 | D accuracy: 50.0] [G loss: 0.8666430711746216]\n",
            "1/1 [==============================] - 1s 553ms/step\n",
            "3 [D loss: 0.41953594982624054 | D accuracy: 96.875] [G loss: 1.012085199356079]\n",
            "1/1 [==============================] - 0s 388ms/step\n",
            "4 [D loss: 0.26211367547512054 | D accuracy: 96.875] [G loss: 0.8854715824127197]\n",
            "1/1 [==============================] - 1s 638ms/step\n",
            "5 [D loss: 0.20461514592170715 | D accuracy: 95.3125] [G loss: 1.1239005327224731]\n",
            "1/1 [==============================] - 1s 596ms/step\n",
            "6 [D loss: 0.08979407697916031 | D accuracy: 100.0] [G loss: 0.906452476978302]\n",
            "1/1 [==============================] - 0s 380ms/step\n",
            "7 [D loss: 0.15592775493860245 | D accuracy: 98.4375] [G loss: 0.6137768030166626]\n",
            "1/1 [==============================] - 0s 385ms/step\n",
            "8 [D loss: 0.07696881890296936 | D accuracy: 98.4375] [G loss: 0.37495315074920654]\n",
            "1/1 [==============================] - 0s 381ms/step\n",
            "9 [D loss: 0.030106596648693085 | D accuracy: 100.0] [G loss: 0.3479394316673279]\n",
            "1/1 [==============================] - 0s 385ms/step\n",
            "10 [D loss: 0.01857971679419279 | D accuracy: 100.0] [G loss: 0.10430645942687988]\n",
            "1/1 [==============================] - 0s 379ms/step\n",
            "11 [D loss: 0.020571143366396427 | D accuracy: 100.0] [G loss: 0.1009669229388237]\n",
            "1/1 [==============================] - 0s 381ms/step\n",
            "12 [D loss: 0.019955926574766636 | D accuracy: 100.0] [G loss: 0.03025122918188572]\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "13 [D loss: 0.011932145338505507 | D accuracy: 100.0] [G loss: 0.02110133320093155]\n",
            "1/1 [==============================] - 1s 547ms/step\n",
            "14 [D loss: 0.02034311555325985 | D accuracy: 100.0] [G loss: 0.007942186668515205]\n",
            "1/1 [==============================] - 0s 432ms/step\n",
            "15 [D loss: 0.005427313037216663 | D accuracy: 100.0] [G loss: 0.012273074127733707]\n",
            "1/1 [==============================] - 0s 404ms/step\n",
            "16 [D loss: 0.004410775611177087 | D accuracy: 100.0] [G loss: 0.010057871229946613]\n",
            "1/1 [==============================] - 0s 385ms/step\n",
            "17 [D loss: 0.006024475209414959 | D accuracy: 100.0] [G loss: 0.01216119434684515]\n",
            "1/1 [==============================] - 1s 700ms/step\n",
            "18 [D loss: 0.020490896655246615 | D accuracy: 100.0] [G loss: 0.001399913104251027]\n",
            "1/1 [==============================] - 0s 413ms/step\n",
            "19 [D loss: 0.006838257249910384 | D accuracy: 100.0] [G loss: 0.00196180772036314]\n",
            "1/1 [==============================] - 0s 401ms/step\n",
            "20 [D loss: 0.005929252598434687 | D accuracy: 100.0] [G loss: 0.005450896918773651]\n",
            "1/1 [==============================] - 1s 645ms/step\n",
            "21 [D loss: 0.005305271712131798 | D accuracy: 100.0] [G loss: 0.005710506811738014]\n",
            "1/1 [==============================] - 0s 408ms/step\n",
            "22 [D loss: 0.007782608503475785 | D accuracy: 100.0] [G loss: 0.009225470013916492]\n",
            "1/1 [==============================] - 1s 647ms/step\n",
            "23 [D loss: 0.008664819411933422 | D accuracy: 100.0] [G loss: 0.017041143029928207]\n",
            "1/1 [==============================] - 0s 350ms/step\n",
            "24 [D loss: 0.025145920924842358 | D accuracy: 100.0] [G loss: 0.08699455112218857]\n",
            "1/1 [==============================] - 0s 388ms/step\n",
            "25 [D loss: 0.007527061505243182 | D accuracy: 100.0] [G loss: 0.24674345552921295]\n",
            "1/1 [==============================] - 0s 385ms/step\n",
            "26 [D loss: 0.09205685928463936 | D accuracy: 96.875] [G loss: 0.38365864753723145]\n",
            "1/1 [==============================] - 0s 403ms/step\n",
            "27 [D loss: 0.01320456201210618 | D accuracy: 100.0] [G loss: 1.9193421602249146]\n",
            "1/1 [==============================] - 0s 393ms/step\n",
            "28 [D loss: 0.18821390345692635 | D accuracy: 95.3125] [G loss: 10.555654525756836]\n",
            "1/1 [==============================] - 1s 620ms/step\n",
            "29 [D loss: 0.45601004362106323 | D accuracy: 81.25] [G loss: 2.768585205078125]\n",
            "1/1 [==============================] - 0s 418ms/step\n",
            "30 [D loss: 0.012868443445768207 | D accuracy: 100.0] [G loss: 4.18491792678833]\n",
            "1/1 [==============================] - 0s 387ms/step\n",
            "31 [D loss: 0.05868908655247651 | D accuracy: 98.4375] [G loss: 8.365315437316895]\n",
            "1/1 [==============================] - 1s 655ms/step\n",
            "32 [D loss: 0.5752572566270828 | D accuracy: 89.0625] [G loss: 11.806410789489746]\n",
            "1/1 [==============================] - 0s 369ms/step\n",
            "33 [D loss: 1.767835259437561 | D accuracy: 35.9375] [G loss: 25.94788360595703]\n",
            "1/1 [==============================] - 0s 362ms/step\n",
            "34 [D loss: 2.6566948132294783 | D accuracy: 73.4375] [G loss: 10.326371192932129]\n",
            "1/1 [==============================] - 1s 636ms/step\n",
            "35 [D loss: 0.020980034489184618 | D accuracy: 98.4375] [G loss: 4.457511901855469]\n",
            "1/1 [==============================] - 0s 387ms/step\n",
            "36 [D loss: 0.0915340055944398 | D accuracy: 95.3125] [G loss: 4.105762958526611]\n",
            "1/1 [==============================] - 0s 389ms/step\n",
            "37 [D loss: 0.00719061482232064 | D accuracy: 100.0] [G loss: 4.302325248718262]\n",
            "1/1 [==============================] - 0s 406ms/step\n",
            "38 [D loss: 0.046588269411586225 | D accuracy: 98.4375] [G loss: 5.670301914215088]\n",
            "1/1 [==============================] - 0s 413ms/step\n",
            "39 [D loss: 0.04412352666258812 | D accuracy: 98.4375] [G loss: 4.567661285400391]\n",
            "1/1 [==============================] - 0s 406ms/step\n",
            "40 [D loss: 0.01761477015679702 | D accuracy: 100.0] [G loss: 4.91090726852417]\n",
            "1/1 [==============================] - 1s 644ms/step\n",
            "41 [D loss: 0.017366848420351744 | D accuracy: 100.0] [G loss: 4.1639180183410645]\n",
            "1/1 [==============================] - 0s 384ms/step\n",
            "42 [D loss: 0.573098823428154 | D accuracy: 78.125] [G loss: 10.621044158935547]\n",
            "1/1 [==============================] - 0s 374ms/step\n",
            "43 [D loss: 0.6021847789088497 | D accuracy: 84.375] [G loss: 4.419771194458008]\n",
            "1/1 [==============================] - 1s 647ms/step\n",
            "44 [D loss: 0.0018377627420704812 | D accuracy: 100.0] [G loss: 2.1974220275878906]\n",
            "1/1 [==============================] - 1s 649ms/step\n",
            "45 [D loss: 0.010102422267664224 | D accuracy: 100.0] [G loss: 1.9121485948562622]\n",
            "1/1 [==============================] - 0s 396ms/step\n",
            "46 [D loss: 0.007693222374655306 | D accuracy: 100.0] [G loss: 1.6565601825714111]\n",
            "1/1 [==============================] - 0s 392ms/step\n",
            "47 [D loss: 0.03438115648168605 | D accuracy: 98.4375] [G loss: 2.880221366882324]\n",
            "1/1 [==============================] - 0s 374ms/step\n",
            "48 [D loss: 0.012309717945754528 | D accuracy: 100.0] [G loss: 2.94244647026062]\n",
            "1/1 [==============================] - 0s 398ms/step\n",
            "49 [D loss: 0.004012651043012738 | D accuracy: 100.0] [G loss: 2.006033182144165]\n",
            "1/1 [==============================] - 0s 401ms/step\n",
            "50 [D loss: 0.008491673041135073 | D accuracy: 100.0] [G loss: 1.4411157369613647]\n",
            "1/1 [==============================] - 1s 667ms/step\n",
            "51 [D loss: 0.016461465042084455 | D accuracy: 100.0] [G loss: 1.538715124130249]\n",
            "1/1 [==============================] - 1s 584ms/step\n",
            "52 [D loss: 0.005568003853113623 | D accuracy: 100.0] [G loss: 0.8813673257827759]\n",
            "1/1 [==============================] - 0s 387ms/step\n",
            "53 [D loss: 0.02079814625903964 | D accuracy: 100.0] [G loss: 1.4326934814453125]\n",
            "1/1 [==============================] - 0s 393ms/step\n",
            "54 [D loss: 0.015613912139087915 | D accuracy: 100.0] [G loss: 1.5744308233261108]\n",
            "1/1 [==============================] - 0s 417ms/step\n",
            "55 [D loss: 0.004471503954846412 | D accuracy: 100.0] [G loss: 1.9389928579330444]\n",
            "1/1 [==============================] - 0s 401ms/step\n",
            "56 [D loss: 0.002970728382933885 | D accuracy: 100.0] [G loss: 1.6674399375915527]\n",
            "1/1 [==============================] - 0s 408ms/step\n",
            "57 [D loss: 0.010586613090708852 | D accuracy: 100.0] [G loss: 1.4786205291748047]\n",
            "1/1 [==============================] - 0s 398ms/step\n",
            "58 [D loss: 0.008221289841458201 | D accuracy: 100.0] [G loss: 0.6247871518135071]\n",
            "1/1 [==============================] - 0s 358ms/step\n",
            "59 [D loss: 0.002578887913841754 | D accuracy: 100.0] [G loss: 1.8150850534439087]\n",
            "1/1 [==============================] - 0s 423ms/step\n",
            "60 [D loss: 0.013578843558207154 | D accuracy: 100.0] [G loss: 1.5309534072875977]\n",
            "1/1 [==============================] - 0s 378ms/step\n",
            "61 [D loss: 0.002649398404173553 | D accuracy: 100.0] [G loss: 1.8502368927001953]\n",
            "1/1 [==============================] - 0s 361ms/step\n",
            "62 [D loss: 0.06675303913652897 | D accuracy: 95.3125] [G loss: 0.37078821659088135]\n",
            "1/1 [==============================] - 0s 396ms/step\n",
            "63 [D loss: 0.027479195618070662 | D accuracy: 100.0] [G loss: 1.5795551538467407]\n",
            "1/1 [==============================] - 0s 397ms/step\n",
            "64 [D loss: 0.0008609886426711455 | D accuracy: 100.0] [G loss: 1.8215521574020386]\n",
            "1/1 [==============================] - 0s 379ms/step\n",
            "65 [D loss: 0.0009399314585607499 | D accuracy: 100.0] [G loss: 3.654545307159424]\n",
            "1/1 [==============================] - 1s 609ms/step\n",
            "66 [D loss: 0.000768975616665557 | D accuracy: 100.0] [G loss: 1.2379729747772217]\n",
            "1/1 [==============================] - 0s 408ms/step\n",
            "67 [D loss: 0.0011865856358781457 | D accuracy: 100.0] [G loss: 2.5364198684692383]\n",
            "1/1 [==============================] - 0s 394ms/step\n",
            "68 [D loss: 0.000616714358329773 | D accuracy: 100.0] [G loss: 0.6920960545539856]\n",
            "1/1 [==============================] - 0s 386ms/step\n",
            "69 [D loss: 0.0011389093706384301 | D accuracy: 100.0] [G loss: 0.5105419754981995]\n",
            "1/1 [==============================] - 0s 390ms/step\n",
            "70 [D loss: 0.0009930967389664147 | D accuracy: 100.0] [G loss: 0.6921038031578064]\n",
            "1/1 [==============================] - 0s 390ms/step\n",
            "71 [D loss: 0.001310869527515024 | D accuracy: 100.0] [G loss: 0.7850652933120728]\n",
            "1/1 [==============================] - 1s 599ms/step\n",
            "72 [D loss: 0.008666597306728363 | D accuracy: 100.0] [G loss: 0.5700976848602295]\n",
            "1/1 [==============================] - 0s 387ms/step\n",
            "73 [D loss: 0.003525536638335325 | D accuracy: 100.0] [G loss: 0.6872048377990723]\n",
            "1/1 [==============================] - 0s 392ms/step\n",
            "74 [D loss: 0.0028040304605383426 | D accuracy: 100.0] [G loss: 0.7940319776535034]\n",
            "1/1 [==============================] - 0s 385ms/step\n",
            "75 [D loss: 0.001380506670102477 | D accuracy: 100.0] [G loss: 0.8775085806846619]\n",
            "1/1 [==============================] - 1s 628ms/step\n",
            "76 [D loss: 0.0033728000707924366 | D accuracy: 100.0] [G loss: 0.5458910465240479]\n",
            "1/1 [==============================] - 1s 627ms/step\n",
            "77 [D loss: 0.0011252084950683638 | D accuracy: 100.0] [G loss: 0.818722128868103]\n",
            "1/1 [==============================] - 1s 646ms/step\n",
            "78 [D loss: 0.0005970673009869643 | D accuracy: 100.0] [G loss: 0.782870352268219]\n",
            "1/1 [==============================] - 1s 625ms/step\n",
            "79 [D loss: 0.0012863339361501858 | D accuracy: 100.0] [G loss: 0.5556988716125488]\n",
            "1/1 [==============================] - 0s 391ms/step\n",
            "80 [D loss: 0.0026426093536429107 | D accuracy: 100.0] [G loss: 0.4878779947757721]\n",
            "1/1 [==============================] - 0s 382ms/step\n",
            "81 [D loss: 0.001776867529770243 | D accuracy: 100.0] [G loss: 0.8029999732971191]\n",
            "1/1 [==============================] - 1s 709ms/step\n",
            "82 [D loss: 0.001298351533478126 | D accuracy: 100.0] [G loss: 0.8274089097976685]\n",
            "1/1 [==============================] - 1s 661ms/step\n",
            "83 [D loss: 0.0011835045297630131 | D accuracy: 100.0] [G loss: 0.5421837568283081]\n",
            "1/1 [==============================] - 0s 435ms/step\n",
            "84 [D loss: 0.0009119844471570104 | D accuracy: 100.0] [G loss: 0.5851641893386841]\n",
            "1/1 [==============================] - 0s 384ms/step\n",
            "85 [D loss: 0.0018066648044623435 | D accuracy: 100.0] [G loss: 0.7416846752166748]\n",
            "1/1 [==============================] - 0s 381ms/step\n",
            "86 [D loss: 0.00047209140757331625 | D accuracy: 100.0] [G loss: 0.23703217506408691]\n",
            "1/1 [==============================] - 0s 351ms/step\n",
            "87 [D loss: 0.0026243761531077325 | D accuracy: 100.0] [G loss: 0.47198575735092163]\n",
            "1/1 [==============================] - 1s 708ms/step\n",
            "88 [D loss: 0.0007043856858217623 | D accuracy: 100.0] [G loss: 0.2309831976890564]\n",
            "1/1 [==============================] - 0s 380ms/step\n",
            "89 [D loss: 0.0007796450518071651 | D accuracy: 100.0] [G loss: 0.4898759126663208]\n",
            "1/1 [==============================] - 0s 386ms/step\n",
            "90 [D loss: 0.0006016227271175012 | D accuracy: 100.0] [G loss: 0.3752122223377228]\n",
            "1/1 [==============================] - 1s 669ms/step\n",
            "91 [D loss: 0.000408745399909094 | D accuracy: 100.0] [G loss: 0.28318116068840027]\n",
            "1/1 [==============================] - 0s 416ms/step\n",
            "92 [D loss: 0.0008471608744002879 | D accuracy: 100.0] [G loss: 0.5586466789245605]\n",
            "1/1 [==============================] - 0s 383ms/step\n",
            "93 [D loss: 0.002377854732912965 | D accuracy: 100.0] [G loss: 0.4260867238044739]\n",
            "1/1 [==============================] - 0s 390ms/step\n",
            "94 [D loss: 0.0012343136477284133 | D accuracy: 100.0] [G loss: 0.6219939589500427]\n",
            "1/1 [==============================] - 0s 379ms/step\n",
            "95 [D loss: 0.00048670716932974756 | D accuracy: 100.0] [G loss: 0.48238420486450195]\n",
            "1/1 [==============================] - 0s 389ms/step\n",
            "96 [D loss: 0.0004325140471337363 | D accuracy: 100.0] [G loss: 0.4525116980075836]\n",
            "1/1 [==============================] - 1s 560ms/step\n",
            "97 [D loss: 0.0025871029938571155 | D accuracy: 100.0] [G loss: 0.46810615062713623]\n",
            "1/1 [==============================] - 0s 388ms/step\n",
            "98 [D loss: 0.0007138362125260755 | D accuracy: 100.0] [G loss: 0.25915563106536865]\n",
            "1/1 [==============================] - 0s 387ms/step\n",
            "99 [D loss: 0.0029556920053437352 | D accuracy: 100.0] [G loss: 0.24160993099212646]\n",
            "1/1 [==============================] - 0s 386ms/step\n",
            "100 [D loss: 0.00025221387477358803 | D accuracy: 100.0] [G loss: 0.15974992513656616]\n",
            "1/1 [==============================] - 0s 389ms/step\n",
            "101 [D loss: 0.001603350741788745 | D accuracy: 100.0] [G loss: 0.3383792042732239]\n",
            "1/1 [==============================] - 1s 653ms/step\n",
            "102 [D loss: 0.00042666382614697795 | D accuracy: 100.0] [G loss: 0.2377554327249527]\n",
            "1/1 [==============================] - 0s 382ms/step\n",
            "103 [D loss: 0.0008097860336420126 | D accuracy: 100.0] [G loss: 0.19286446273326874]\n",
            "1/1 [==============================] - 0s 384ms/step\n",
            "104 [D loss: 0.0013812874676659703 | D accuracy: 100.0] [G loss: 0.1602398306131363]\n",
            "1/1 [==============================] - 0s 392ms/step\n",
            "105 [D loss: 0.0008888310912880115 | D accuracy: 100.0] [G loss: 0.46760910749435425]\n",
            "1/1 [==============================] - 0s 381ms/step\n",
            "106 [D loss: 0.002526116048102267 | D accuracy: 100.0] [G loss: 0.3212240934371948]\n",
            "1/1 [==============================] - 0s 390ms/step\n",
            "107 [D loss: 0.0008001497481018305 | D accuracy: 100.0] [G loss: 0.31347864866256714]\n",
            "1/1 [==============================] - 0s 393ms/step\n",
            "108 [D loss: 0.001264810113752901 | D accuracy: 100.0] [G loss: 0.38771045207977295]\n",
            "1/1 [==============================] - 0s 397ms/step\n",
            "109 [D loss: 0.0003456348567851819 | D accuracy: 100.0] [G loss: 0.24600602686405182]\n",
            "1/1 [==============================] - 1s 666ms/step\n",
            "110 [D loss: 0.0005045196885475889 | D accuracy: 100.0] [G loss: 0.39500024914741516]\n",
            "1/1 [==============================] - 0s 387ms/step\n",
            "111 [D loss: 0.00031557159672956914 | D accuracy: 100.0] [G loss: 0.32242757081985474]\n",
            "1/1 [==============================] - 0s 384ms/step\n",
            "112 [D loss: 0.0002674352481335518 | D accuracy: 100.0] [G loss: 0.16376635432243347]\n",
            "1/1 [==============================] - 0s 400ms/step\n",
            "113 [D loss: 0.0009451635123696178 | D accuracy: 100.0] [G loss: 0.4127666652202606]\n",
            "1/1 [==============================] - 0s 391ms/step\n",
            "114 [D loss: 0.00036986909617553465 | D accuracy: 100.0] [G loss: 0.305112361907959]\n",
            "1/1 [==============================] - 0s 382ms/step\n",
            "115 [D loss: 0.00022354892280418426 | D accuracy: 100.0] [G loss: 0.2547329068183899]\n",
            "1/1 [==============================] - 1s 772ms/step\n",
            "116 [D loss: 0.0005661395261995494 | D accuracy: 100.0] [G loss: 0.3341405689716339]\n",
            "1/1 [==============================] - 0s 359ms/step\n",
            "117 [D loss: 0.0007073119631968439 | D accuracy: 100.0] [G loss: 0.4429275393486023]\n",
            "1/1 [==============================] - 0s 392ms/step\n",
            "118 [D loss: 0.00034659642551559955 | D accuracy: 100.0] [G loss: 0.2677465081214905]\n",
            "1/1 [==============================] - 1s 654ms/step\n",
            "119 [D loss: 0.0015589975228067487 | D accuracy: 100.0] [G loss: 0.3836825489997864]\n",
            "1/1 [==============================] - 0s 389ms/step\n",
            "120 [D loss: 0.000957252639636863 | D accuracy: 100.0] [G loss: 0.33661818504333496]\n",
            "1/1 [==============================] - 0s 364ms/step\n",
            "121 [D loss: 0.0001797844161046669 | D accuracy: 100.0] [G loss: 0.44080156087875366]\n",
            "1/1 [==============================] - 0s 405ms/step\n",
            "122 [D loss: 0.000543635254871333 | D accuracy: 100.0] [G loss: 0.1525590717792511]\n",
            "1/1 [==============================] - 1s 726ms/step\n",
            "123 [D loss: 0.00023990036061150022 | D accuracy: 100.0] [G loss: 0.22660551965236664]\n",
            "1/1 [==============================] - 0s 379ms/step\n",
            "124 [D loss: 0.00030666384554933757 | D accuracy: 100.0] [G loss: 0.12210661172866821]\n",
            "1/1 [==============================] - 0s 469ms/step\n",
            "125 [D loss: 0.000745580910006538 | D accuracy: 100.0] [G loss: 0.2716909646987915]\n",
            "1/1 [==============================] - 0s 385ms/step\n",
            "126 [D loss: 0.0003646390832727775 | D accuracy: 100.0] [G loss: 0.22651925683021545]\n",
            "1/1 [==============================] - 0s 440ms/step\n",
            "127 [D loss: 0.000840369779325556 | D accuracy: 100.0] [G loss: 0.2792746424674988]\n",
            "1/1 [==============================] - 1s 685ms/step\n",
            "128 [D loss: 0.00018395233200863004 | D accuracy: 100.0] [G loss: 0.25999942421913147]\n",
            "1/1 [==============================] - 1s 674ms/step\n",
            "129 [D loss: 0.0010390662064310163 | D accuracy: 100.0] [G loss: 0.10885049402713776]\n",
            "1/1 [==============================] - 1s 694ms/step\n",
            "130 [D loss: 0.00026242171861667885 | D accuracy: 100.0] [G loss: 0.2974458634853363]\n",
            "1/1 [==============================] - 0s 385ms/step\n",
            "131 [D loss: 0.0006601527566090226 | D accuracy: 100.0] [G loss: 0.12417689710855484]\n",
            "1/1 [==============================] - 1s 642ms/step\n",
            "132 [D loss: 0.0003351900559209753 | D accuracy: 100.0] [G loss: 0.1735689342021942]\n",
            "1/1 [==============================] - 0s 399ms/step\n",
            "133 [D loss: 0.00010100422514369711 | D accuracy: 100.0] [G loss: 0.13139961659908295]\n",
            "1/1 [==============================] - 0s 401ms/step\n",
            "134 [D loss: 0.0009540500759612769 | D accuracy: 100.0] [G loss: 0.2772377133369446]\n",
            "1/1 [==============================] - 0s 399ms/step\n",
            "135 [D loss: 0.0015251123404596 | D accuracy: 100.0] [G loss: 0.11441635340452194]\n",
            "1/1 [==============================] - 1s 660ms/step\n",
            "136 [D loss: 0.0002144087411579676 | D accuracy: 100.0] [G loss: 0.19079191982746124]\n",
            "1/1 [==============================] - 1s 653ms/step\n",
            "137 [D loss: 0.00016804759798105806 | D accuracy: 100.0] [G loss: 0.14463326334953308]\n",
            "1/1 [==============================] - 1s 648ms/step\n",
            "138 [D loss: 0.00016565043188165873 | D accuracy: 100.0] [G loss: 0.26019471883773804]\n",
            "1/1 [==============================] - 1s 554ms/step\n",
            "139 [D loss: 0.00011140143578813877 | D accuracy: 100.0] [G loss: 0.1384720802307129]\n",
            "1/1 [==============================] - 0s 392ms/step\n",
            "140 [D loss: 0.00014159275815472938 | D accuracy: 100.0] [G loss: 0.19619140028953552]\n",
            "1/1 [==============================] - 0s 406ms/step\n",
            "141 [D loss: 0.00023877600506239105 | D accuracy: 100.0] [G loss: 0.12613070011138916]\n",
            "1/1 [==============================] - 0s 377ms/step\n",
            "142 [D loss: 0.0004013240759377368 | D accuracy: 100.0] [G loss: 0.14133161306381226]\n",
            "1/1 [==============================] - 0s 365ms/step\n",
            "143 [D loss: 0.0008748747932258993 | D accuracy: 100.0] [G loss: 0.13415907323360443]\n",
            "1/1 [==============================] - 0s 408ms/step\n",
            "144 [D loss: 0.00013055992894805968 | D accuracy: 100.0] [G loss: 0.2627062499523163]\n",
            "1/1 [==============================] - 0s 401ms/step\n",
            "145 [D loss: 0.0001341813876933884 | D accuracy: 100.0] [G loss: 0.09917773306369781]\n",
            "1/1 [==============================] - 0s 380ms/step\n",
            "146 [D loss: 0.0002404344813839998 | D accuracy: 100.0] [G loss: 0.1160503551363945]\n",
            "1/1 [==============================] - 0s 380ms/step\n",
            "147 [D loss: 0.0002926370316345128 | D accuracy: 100.0] [G loss: 0.12858888506889343]\n",
            "1/1 [==============================] - 1s 534ms/step\n",
            "148 [D loss: 0.00017577941616764292 | D accuracy: 100.0] [G loss: 0.05052786320447922]\n",
            "1/1 [==============================] - 0s 396ms/step\n",
            "149 [D loss: 0.001487801651819609 | D accuracy: 100.0] [G loss: 0.10000790655612946]\n",
            "1/1 [==============================] - 0s 405ms/step\n",
            "150 [D loss: 0.0002596085978439078 | D accuracy: 100.0] [G loss: 0.07736027240753174]\n",
            "1/1 [==============================] - 1s 634ms/step\n",
            "151 [D loss: 0.0001113099833673914 | D accuracy: 100.0] [G loss: 0.08622848242521286]\n",
            "1/1 [==============================] - 0s 395ms/step\n",
            "152 [D loss: 0.00037430634984048083 | D accuracy: 100.0] [G loss: 0.09834587574005127]\n",
            "1/1 [==============================] - 0s 395ms/step\n",
            "153 [D loss: 0.00018556142276793253 | D accuracy: 100.0] [G loss: 0.11066748946905136]\n",
            "1/1 [==============================] - 0s 368ms/step\n",
            "154 [D loss: 0.00033171683026012033 | D accuracy: 100.0] [G loss: 0.07591600716114044]\n",
            "1/1 [==============================] - 0s 352ms/step\n",
            "155 [D loss: 0.008879173488821834 | D accuracy: 100.0] [G loss: 0.024550067260861397]\n",
            "1/1 [==============================] - 0s 354ms/step\n",
            "156 [D loss: 0.00044916063848177146 | D accuracy: 100.0] [G loss: 0.01053736824542284]\n",
            "1/1 [==============================] - 0s 386ms/step\n",
            "157 [D loss: 0.00041034992136701476 | D accuracy: 100.0] [G loss: 0.021845338866114616]\n",
            "1/1 [==============================] - 0s 427ms/step\n",
            "158 [D loss: 0.0005312801604304696 | D accuracy: 100.0] [G loss: 0.01275414228439331]\n",
            "1/1 [==============================] - 0s 383ms/step\n",
            "159 [D loss: 8.141290368257614e-05 | D accuracy: 100.0] [G loss: 0.031481560319662094]\n",
            "1/1 [==============================] - 1s 591ms/step\n",
            "160 [D loss: 0.002861731049051741 | D accuracy: 100.0] [G loss: 0.08996114879846573]\n",
            "1/1 [==============================] - 0s 403ms/step\n",
            "161 [D loss: 0.00016893436259124428 | D accuracy: 100.0] [G loss: 0.21076804399490356]\n",
            "1/1 [==============================] - 0s 378ms/step\n",
            "162 [D loss: 4.0497789086657576e-05 | D accuracy: 100.0] [G loss: 0.24360671639442444]\n",
            "1/1 [==============================] - 0s 366ms/step\n",
            "163 [D loss: 1.9712357698153937e-05 | D accuracy: 100.0] [G loss: 0.17493391036987305]\n",
            "1/1 [==============================] - 0s 396ms/step\n",
            "164 [D loss: 8.009090925042983e-05 | D accuracy: 100.0] [G loss: 0.10765429586172104]\n",
            "1/1 [==============================] - 1s 653ms/step\n",
            "165 [D loss: 0.0006335934849630576 | D accuracy: 100.0] [G loss: 0.17570653557777405]\n",
            "1/1 [==============================] - 1s 674ms/step\n",
            "166 [D loss: 0.00013361883065954316 | D accuracy: 100.0] [G loss: 0.12096579372882843]\n",
            "1/1 [==============================] - 0s 396ms/step\n",
            "167 [D loss: 3.026137619599467e-05 | D accuracy: 100.0] [G loss: 0.08761011064052582]\n",
            "1/1 [==============================] - 0s 409ms/step\n",
            "168 [D loss: 0.001052093764883466 | D accuracy: 100.0] [G loss: 0.07603918015956879]\n",
            "1/1 [==============================] - 0s 384ms/step\n",
            "169 [D loss: 3.712999406957351e-05 | D accuracy: 100.0] [G loss: 0.11008138954639435]\n",
            "1/1 [==============================] - 1s 667ms/step\n",
            "170 [D loss: 4.930020759275067e-05 | D accuracy: 100.0] [G loss: 0.07397148013114929]\n",
            "1/1 [==============================] - 0s 478ms/step\n",
            "171 [D loss: 0.00024161628243746236 | D accuracy: 100.0] [G loss: 0.04987387731671333]\n",
            "1/1 [==============================] - 0s 399ms/step\n",
            "172 [D loss: 0.00014150429160508793 | D accuracy: 100.0] [G loss: 0.0984940230846405]\n",
            "1/1 [==============================] - 0s 402ms/step\n",
            "173 [D loss: 0.00019300144958833698 | D accuracy: 100.0] [G loss: 0.10811900347471237]\n",
            "1/1 [==============================] - 0s 367ms/step\n",
            "174 [D loss: 4.748506944451947e-05 | D accuracy: 100.0] [G loss: 0.06301496177911758]\n",
            "1/1 [==============================] - 0s 387ms/step\n",
            "175 [D loss: 4.872339695793926e-05 | D accuracy: 100.0] [G loss: 0.08312062919139862]\n",
            "1/1 [==============================] - 1s 512ms/step\n",
            "176 [D loss: 4.4495643123809714e-05 | D accuracy: 100.0] [G loss: 0.06276074051856995]\n",
            "1/1 [==============================] - 0s 369ms/step\n",
            "177 [D loss: 4.6587991619162494e-05 | D accuracy: 100.0] [G loss: 0.057578787207603455]\n",
            "1/1 [==============================] - 0s 383ms/step\n",
            "178 [D loss: 5.86570608902548e-05 | D accuracy: 100.0] [G loss: 0.04929003864526749]\n",
            "1/1 [==============================] - 0s 413ms/step\n",
            "179 [D loss: 4.19473053625552e-05 | D accuracy: 100.0] [G loss: 0.025035198777914047]\n",
            "1/1 [==============================] - 0s 388ms/step\n",
            "180 [D loss: 8.939669351093471e-05 | D accuracy: 100.0] [G loss: 0.04959985241293907]\n",
            "1/1 [==============================] - 0s 380ms/step\n",
            "181 [D loss: 0.00031222274992614985 | D accuracy: 100.0] [G loss: 0.045743927359580994]\n",
            "1/1 [==============================] - 1s 693ms/step\n",
            "182 [D loss: 6.792288627366361e-05 | D accuracy: 100.0] [G loss: 0.0931699350476265]\n",
            "1/1 [==============================] - 1s 685ms/step\n",
            "183 [D loss: 0.00016856885486049578 | D accuracy: 100.0] [G loss: 0.09128028899431229]\n",
            "1/1 [==============================] - 1s 639ms/step\n",
            "184 [D loss: 9.643868907005526e-05 | D accuracy: 100.0] [G loss: 0.04728566110134125]\n",
            "1/1 [==============================] - 0s 388ms/step\n",
            "185 [D loss: 8.621652341389563e-05 | D accuracy: 100.0] [G loss: 0.0554712638258934]\n",
            "1/1 [==============================] - 0s 376ms/step\n",
            "186 [D loss: 0.00014921411138857366 | D accuracy: 100.0] [G loss: 0.049992114305496216]\n",
            "1/1 [==============================] - 0s 433ms/step\n",
            "187 [D loss: 7.500238461943809e-05 | D accuracy: 100.0] [G loss: 0.021787017583847046]\n",
            "1/1 [==============================] - 0s 379ms/step\n",
            "188 [D loss: 9.406586650584359e-05 | D accuracy: 100.0] [G loss: 0.08726785331964493]\n",
            "1/1 [==============================] - 1s 694ms/step\n",
            "189 [D loss: 0.0001409707692801021 | D accuracy: 100.0] [G loss: 0.05263495072722435]\n",
            "1/1 [==============================] - 1s 653ms/step\n",
            "190 [D loss: 0.00011212333629373461 | D accuracy: 100.0] [G loss: 0.036852508783340454]\n",
            "1/1 [==============================] - 1s 523ms/step\n",
            "191 [D loss: 0.00013178390872781165 | D accuracy: 100.0] [G loss: 0.055242449045181274]\n",
            "1/1 [==============================] - 0s 395ms/step\n",
            "192 [D loss: 0.00013532998855225742 | D accuracy: 100.0] [G loss: 0.06760285794734955]\n",
            "1/1 [==============================] - 0s 398ms/step\n",
            "193 [D loss: 0.0003928732294298243 | D accuracy: 100.0] [G loss: 0.031805962324142456]\n",
            "1/1 [==============================] - 0s 402ms/step\n",
            "194 [D loss: 5.655490667777485e-05 | D accuracy: 100.0] [G loss: 0.1381632536649704]\n",
            "1/1 [==============================] - 1s 695ms/step\n",
            "195 [D loss: 5.3355870477389544e-05 | D accuracy: 100.0] [G loss: 0.025980856269598007]\n",
            "1/1 [==============================] - 0s 403ms/step\n",
            "196 [D loss: 5.860001692781225e-05 | D accuracy: 100.0] [G loss: 0.06673069298267365]\n",
            "1/1 [==============================] - 0s 426ms/step\n",
            "197 [D loss: 0.00011808440103777684 | D accuracy: 100.0] [G loss: 0.08091159164905548]\n",
            "1/1 [==============================] - 0s 408ms/step\n",
            "198 [D loss: 0.00030103777226031525 | D accuracy: 100.0] [G loss: 0.06937352567911148]\n",
            "1/1 [==============================] - 0s 386ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "199 [D loss: 0.00014337031097966246 | D accuracy: 100.0] [G loss: 0.03186294063925743]\n"
          ]
        }
      ],
      "source": [
        "!pip install faker lorem-text Pillow\n",
        "!pip install pandas\n",
        "import os\n",
        "import csv\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from faker import Faker\n",
        "from lorem_text import lorem\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, LeakyReLU, Flatten, Dense, Dropout\n",
        "from keras.layers import BatchNormalization, Reshape, Conv2DTranspose\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "img_rows = 64\n",
        "img_cols = 64\n",
        "channels = 3\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "noise_dim = 100\n",
        "\n",
        "def load_images_and_profiles(image_folder, csv_file, img_shape):\n",
        "    profiles = pd.read_csv(csv_file)\n",
        "    images = []\n",
        "    labels = []\n",
        "    profile_infos = []\n",
        "\n",
        "    for _, row in profiles.iterrows():\n",
        "        img_path = row['image_path']\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            print(f\"Warning: Failed to load image: {img_path}\")\n",
        "            continue\n",
        "        img = cv2.resize(img, (img_shape[1], img_shape[0]))\n",
        "        images.append(img)\n",
        "        profile_infos.append(row.drop(['image_path']).values)\n",
        "        labels.append(0 if 'real' in img_path else 1)\n",
        "\n",
        "    images = np.array(images) / 127.5 - 1.0\n",
        "    labels = np.array(labels)\n",
        "    profile_infos = np.array(profile_infos)\n",
        "    return images, labels, profile_infos\n",
        "\n",
        "# Paths to your folders and CSV files\n",
        "fake_csv_file = '/content/drive/MyDrive/Fake Profile Dectection/fake_profiles.csv'\n",
        "real_csv_file = '/content/drive/MyDrive/Fake Profile Dectection/real_profiles.csv'\n",
        "fake_image_folder = '/content/drive/MyDrive/Fake Profile Dectection/fake'\n",
        "real_image_folder = '/content/drive/MyDrive/Fake Profile Dectection/real'\n",
        "# Build the Discriminator\n",
        "def build_discriminator(profile_input_shape):\n",
        "    img_input = tf.keras.Input(shape=img_shape)\n",
        "    profile_input = tf.keras.Input(shape=profile_input_shape)\n",
        "\n",
        "    x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(img_input)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "\n",
        "    x = Conv2D(256, kernel_size=3, strides=2, padding=\"same\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = BatchNormalization(momentum=0.8)(x)\n",
        "\n",
        "    x = Conv2D(512, kernel_size=3, strides=1, padding=\"same\")(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    profile_features = Dense(x.shape[1])(profile_input)  # Match the dimensionality of the flattened image data\n",
        "    profile_features = LeakyReLU(alpha=0.2)(profile_features)\n",
        "    profile_features = Dropout(0.25)(profile_features)\n",
        "\n",
        "    combined_features = tf.keras.layers.Concatenate()([x, profile_features])\n",
        "    combined_features = Dense(512)(combined_features)\n",
        "    combined_features = LeakyReLU(alpha=0.2)(combined_features)\n",
        "    combined_features = Dropout(0.25)(combined_features)\n",
        "\n",
        "    output = Dense(1, activation='sigmoid')(combined_features)\n",
        "\n",
        "    model = tf.keras.Model([img_input, profile_input], output)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Build the Generator\n",
        "def build_generator():\n",
        "    model = Sequential([\n",
        "        Dense(128 * 16 * 16, activation=\"relu\", input_dim=noise_dim),\n",
        "        Reshape((16, 16, 128)),\n",
        "        BatchNormalization(momentum=0.8),\n",
        "        Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        BatchNormalization(momentum=0.8),\n",
        "        Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"),\n",
        "        LeakyReLU(alpha=0.2),\n",
        "        BatchNormalization(momentum=0.8),\n",
        "        Conv2DTranspose(3, kernel_size=4, strides=1, padding=\"same\", activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/My Drive/Fake Profile Dectection'\n",
        "# Load datasets\n",
        "real_images, real_labels, real_profiles = load_images_and_profiles(real_image_folder, real_csv_file, img_shape)\n",
        "fake_images, fake_labels, fake_profiles = load_images_and_profiles(fake_image_folder, fake_csv_file, img_shape)\n",
        "\n",
        "# Combine datasets\n",
        "images = np.concatenate((real_images, fake_images))\n",
        "labels = np.concatenate((real_labels, fake_labels))\n",
        "profiles = np.concatenate((real_profiles, fake_profiles))\n",
        "\n",
        "# Convert profile data to numerical representation (example using one-hot encoding)\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "encoder = OneHotEncoder()\n",
        "profiles_encoded = encoder.fit_transform(profiles).toarray()\n",
        "\n",
        "# Split into training and testing sets\n",
        "x_train, x_test, y_train, y_test, profile_train_encoded, profile_test_encoded = train_test_split(\n",
        "    images, labels, profiles_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "discriminator = build_discriminator(profile_train_encoded.shape[1:])\n",
        "generator = build_generator()\n",
        "\n",
        "# Combine models for GAN\n",
        "discriminator.trainable = False\n",
        "z = tf.keras.Input(shape=(noise_dim,))\n",
        "profile_input = tf.keras.Input(shape=profile_train_encoded.shape[1:]) # Use the encoded profile shape\n",
        "img = generator(z)\n",
        "validity = discriminator([img, profile_input]) # Pass profile input to discriminator\n",
        "combined = tf.keras.Model([z, profile_input], validity) # Include profile input in combined model\n",
        "combined.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5))\n",
        "\n",
        "# Training the GAN\n",
        "# Training the GAN\n",
        "def train_gan(generator, discriminator, combined, x_train, profile_train, epochs=2000, batch_size=32, save_interval=1000):\n",
        "    # Adversarial ground truths\n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Train Discriminator\n",
        "        idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "        real_imgs = x_train[idx]\n",
        "        real_profiles = profile_train[idx]\n",
        "\n",
        "        noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "        gen_imgs = generator.predict(noise)\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch([real_imgs, real_profiles], valid)\n",
        "        d_loss_fake = discriminator.train_on_batch([gen_imgs, real_profiles], fake)\n",
        "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "        # Train Generator\n",
        "        noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "        # Pass both noise and corresponding profile data to the combined model\n",
        "        g_loss = combined.train_on_batch([noise, real_profiles], valid) # Pass profile data here\n",
        "\n",
        "        # Print progress\n",
        "        print(f\"{epoch} [D loss: {d_loss[0]} | D accuracy: {d_loss[1] * 100}] [G loss: {g_loss}]\")\n",
        "\n",
        "        # Save generated image samples at intervals\n",
        "        if epoch % save_interval == 0:\n",
        "            # Define the save_imgs function here\n",
        "            def save_imgs(generator, epoch):\n",
        "                r, c = 5, 5\n",
        "                noise = np.random.normal(0, 1, (r * c, noise_dim))\n",
        "                gen_imgs = generator.predict(noise)\n",
        "\n",
        "                # Rescale images 0 - 1\n",
        "                gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "                fig, axs = plt.subplots(r, c)\n",
        "                cnt = 0\n",
        "                for i in range(r):\n",
        "                    for j in range(c):\n",
        "                        axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
        "                        axs[i,j].axis('off')\n",
        "                        cnt += 1\n",
        "                fig.savefig(\"/content/drive/MyDrive/Fake Profile Dectection/fake/fake_%d.png\" % epoch)\n",
        "                plt.close()\n",
        "\n",
        "            save_imgs(generator, epoch) # Call the newly defined function\n",
        "\n",
        "        # Save model weights at intervals\n",
        "        if epoch % save_interval == 0:\n",
        "            discriminator.save_weights('/content/drive/MyDrive/Fake Profile Dectection/discriminator_weights.h5')\n",
        "            generator.save_weights('/content/drive/MyDrive/Fake Profile Dectection/generator_weights.h5')\n",
        "\n",
        "train_gan(generator, discriminator, combined, x_train, profile_train_encoded, epochs=200, batch_size=32, save_interval=1000)\n",
        "\n",
        "# Save the models after training\n",
        "generator.save('/content/drive/MyDrive/Fake Profile Dectection/generator_model.h5')\n",
        "discriminator.save('/content/drive/MyDrive/Fake Profile Dectection/discriminator_model.h5')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GuydpeVrsCyH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c83fdf0-80fb-4b51-b0fc-aaa9d59ad8a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved models\n",
        "generator = load_model('/content/drive/MyDrive/Fake Profile Dectection/generator_model.h5')\n",
        "discriminator = load_model('/content/drive/MyDrive/Fake Profile Dectection/discriminator_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tgDYHwmCscVB"
      },
      "outputs": [],
      "source": [
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(0.0002, 0.5), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BZHaUJEUskP8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0cfea03-50c7-4e3b-d9f1-7c79212abe6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 4s 338ms/step\n"
          ]
        }
      ],
      "source": [
        "def generate_fake_images(generator, profile_data, noise_dim=100):\n",
        "    noise = np.random.normal(0, 1, (profile_data.shape[0], noise_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    return gen_imgs\n",
        "\n",
        "# Assuming profile_test_encoded is already defined and contains the test profile data\n",
        "fake_images = generate_fake_images(generator, profile_test_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LPuY7MXMsszT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c93aac-733c-4234-cfa2-9799638ca40a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 6s 570ms/step\n",
            "10/10 [==============================] - 6s 591ms/step\n"
          ]
        }
      ],
      "source": [
        "def predict_profiles(discriminator, images, profile_data):\n",
        "    predictions = discriminator.predict([images, profile_data])\n",
        "    return predictions\n",
        "\n",
        "# Predict real and fake profiles\n",
        "real_predictions = predict_profiles(discriminator, x_test, profile_test_encoded)\n",
        "fake_predictions = predict_profiles(discriminator, fake_images, profile_test_encoded)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "cNS9I4NTs2K4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f1874e-47b4-4322-aa7e-846226e3b346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9795918367346939\n",
            "Confusion Matrix:\n",
            "[[282  12]\n",
            " [  0 294]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Binarize predictions\n",
        "real_predictions_bin = (real_predictions > 0.5).astype(int)\n",
        "fake_predictions_bin = (fake_predictions > 0.5).astype(int)\n",
        "\n",
        "# True labels\n",
        "true_labels_real = np.zeros(x_test.shape[0])\n",
        "true_labels_fake = np.ones(fake_images.shape[0])\n",
        "\n",
        "# Combine predictions and labels\n",
        "combined_predictions = np.concatenate((real_predictions_bin, fake_predictions_bin))\n",
        "combined_labels = np.concatenate((true_labels_real, true_labels_fake))\n",
        "\n",
        "# Evaluate\n",
        "accuracy = accuracy_score(combined_labels, combined_predictions)\n",
        "conf_matrix = confusion_matrix(combined_labels, combined_predictions)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save models\n",
        "discriminator.save('/content/drive/MyDrive/Fake Profile Dectection/discriminator_model.h5')\n",
        "generator.save('/content/drive/MyDrive/Fake Profile Dectection/generator_model.h5')\n",
        "\n",
        "# Load models\n",
        "from keras.models import load_model\n",
        "discriminator = load_model('/content/drive/MyDrive/Fake Profile Dectection/discriminator_model.h5')\n",
        "generator = load_model('/content/drive/MyDrive/Fake Profile Dectection/generator_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ik03e5JdCOZ",
        "outputId": "49d349b1-ee22-413d-a211-eec3a5c56c0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_and_preprocess_image(image_path, img_shape):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
        "    img = cv2.resize(img, (img_shape[1], img_shape[0]))\n",
        "    img = (img / 127.5) - 1.0  # Normalize image to [-1, 1]\n",
        "    return np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "# Example usage\n",
        "sample_image_path = '/content/drive/MyDrive/Fake Profile Dectection/real/real_00080.jpg'  # Replace with actual path\n",
        "img_shape = (64, 64, 3)  # Shape should match your model's input shape\n",
        "sample_image = load_and_preprocess_image(sample_image_path, img_shape)\n"
      ],
      "metadata": {
        "id": "zAfGuMceeLW9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JqOZcmDPs8PZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce34a4b8-883a-455d-8532-e939c5950faf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# Load the saved models\n",
        "discriminator = load_model('/content/drive/MyDrive/Fake Profile Dectection/discriminator_model.h5')\n",
        "generator = load_model('/content/drive/MyDrive/Fake Profile Dectection/generator_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def load_and_preprocess_image(image_path, img_shape):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Failed to load image: {image_path}\")\n",
        "    img = cv2.resize(img, (img_shape[1], img_shape[0]))\n",
        "    img = (img / 127.5) - 1.0  # Normalize image to [-1, 1]\n",
        "    return np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "def load_profile_info(csv_file, image_name):\n",
        "    profiles = pd.read_csv(csv_file)\n",
        "    # Check if image name (without extension) exists in 'image_path' column\n",
        "    profile_data = profiles[profiles['image_path'].str.contains(image_name.split('.')[0])]\n",
        "    return profile_data.drop(columns=['image_path']).values\n",
        "\n",
        "# Example usage - Adjust the paths and image name accordingly\n",
        "sample_image_path = '/content/drive/MyDrive/Fake Profile Dectection/fake/easy_224_1100.jpg'\n",
        "img_shape = (64, 64, 3)\n",
        "sample_image = load_and_preprocess_image(sample_image_path, img_shape)\n",
        "\n",
        "# Extract the image name from the path (without extension)\n",
        "sample_image_name = sample_image_path.split('/')[-1].split('.')[0]\n",
        "sample_profile_info = load_profile_info('/content/drive/MyDrive/Fake Profile Dectection/real_profiles.csv', sample_image_name)\n",
        "\n",
        "if sample_profile_info.size == 0:\n",
        "    print(f\"No profile information found for {sample_image_name}. Check if the image name is present in the CSV file.\")\n",
        "else:\n",
        "    # Convert profile data to numerical representation\n",
        "    encoder = OneHotEncoder()  # Initialize OneHotEncoder here\n",
        "    sample_profile_encoded = encoder.fit_transform(sample_profile_info).toarray()\n",
        "\n",
        "    # Check if the shape of the encoded profile matches what the discriminator expects\n",
        "    expected_input_shape = discriminator.input_shape[1][1]  # Get the expected shape from the discriminator model\n",
        "    if sample_profile_encoded.shape[1] != expected_input_shape:\n",
        "        print(f\"Warning: Profile data shape ({sample_profile_encoded.shape[1]}) does not match expected input shape ({expected_input_shape})\")\n",
        "        # Handle the mismatch here, e.g., by resizing the encoded profile or adjusting your model\n",
        "\n",
        "    print(sample_profile_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnXXzOreeqqw",
        "outputId": "76759bda-f551-46c2-a752-b09150eea3da"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No profile information found for easy_224_1100. Check if the image name is present in the CSV file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_image(discriminator, image, profile_encoded):\n",
        "    if profile_encoded is None:\n",
        "        print(\"Cannot classify image without profile information.\")\n",
        "        return None\n",
        "\n",
        "    # Reshape profile_encoded to match the expected input shape of the discriminator\n",
        "    profile_encoded = np.reshape(profile_encoded, (1, -1))  # Flatten the array\n",
        "    # Pad the profile_encoded array with zeros to match the expected size\n",
        "    expected_size = discriminator.input_shape[1][1]\n",
        "    profile_encoded = np.pad(profile_encoded, [(0, 0), (0, expected_size - profile_encoded.shape[1])])\n",
        "\n",
        "    prediction = discriminator.predict([image, profile_encoded])\n",
        "    return prediction\n",
        "\n",
        "# Predict the class of the sample image\n",
        "prediction = classify_image(discriminator, sample_image, sample_profile_encoded)\n",
        "if prediction is not None:\n",
        "    print(\"Prediction (0: Real, 1: Fake):\", prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R55Bx71De825",
        "outputId": "f21d9429-4c60-4622-d7b1-5f3bd413c5c5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Prediction (0: Real, 1: Fake): [[0.02309068]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p5mrf2wxfcTp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}